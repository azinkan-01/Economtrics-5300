---
title: "EDA"
author: "Andrew Zinkan"
date: "8/3/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, ech0 = FALSE, results= "hide", message=FALSE, warning=FALSE}
# Load initial packages
install.packages('timetk')
library(tidyverse)
library(ggplot2)
library(dplyr)
library(vtable)
library(fixest)
library(Hmisc)
library(timetk)
library(tidyr)
```

#### _Load Data Transfromation Files_
```{r, results= "hide", message=FALSE, warning=FALSE}
google_trends_master <-  read.csv("Generated_data/google_trends_master.csv", na.strings = c("","NA","NULL",NULL))
shool_master <- read.csv("Generated_data/shool_master.csv", na.strings = c("","NA","NULL",NULL))

```

```{r, echo = FALSE ,results= "hide", message=FALSE, warning=FALSE}
google_trends_master <- google_trends_master %>% 
  mutate(start_of_week = as.Date(start_of_week, format="%Y-%m-%d")) %>% 
  mutate(end_of_week = as.Date(end_of_week, format="%Y-%m-%d"))
  
```

## Describe data
#### _Google Trends_

```{r}
# schname
di <- describe(google_trends_master)
print(di[3])
```
```{r}
# time frame data
di <- describe(google_trends_master)
print(di[5:6])
```
```{r}
# index info
di <- describe(google_trends_master)
print(di[7:9])
```
```{r}
# normalized index info
di <- describe(google_trends_master)
print(di[11])
```
```{r, echo=FALSE, results= "hide", warning = FALSE}

# plot density for the index rankings
ggplot(google_trends_master, aes(x= as.numeric(index), fill=after_score_card, alpha = 0.4)) + 
  geom_density()

```

```{r, echo=FALSE, results= "hide", warning = FALSE}



```

## index over time

```{r}
# plot 

```


## Identify "high-earning" and "low-earning" Earning Schools
Our research questions states “high-earning” vs “low-earning” colleges earning, so how can we define “high” vs “low”?
Earning Variables of interest:

- mn_earn_wne_p10
- md_earn_wne_p10-REPORTED-EARNINGS (One that was called to attention for the project)
- pct10_earn_wne_p10
- pct25_earn_wne_p10
- pct75_earn_wne_p10
- pct90_earn_wne_p10
- sd_earn_wne_p10
- count_wne_inc1_p10
- count_wne_inc2_p10
- count_wne_inc3_p10

#### _Distributions on earnings among colleges_
```{r}
# Histogram overlaid with kernel density curve
ggplot(shool_master, aes(x=md_reported_ern_10yr)) +
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
                   binwidth=100,
                   colour="black", fill="white") +
    geom_density(alpha=.2, fill="#FF6666", stat="count")  # Overlay with transparent density plot
```

This graph represents the density of "median earnings of graduates ten years after graduation for each college".
Density in this case is the count of colleges that fall in that earning spectrum.

This plot has a lot of noise in it though so lets smooth it out. 
```{r}
ggplot(shool_master, aes(x= as.numeric(md_reported_ern_10yr))) + geom_density()

```

Now that the data is smoothed we get a better perspective of the distribution of earnings. 
We can see tho that this data is skewed to the right, indicating that while most schools median earning 10 years after graduation tends to fall right around 40,000 we have select schools who report very high earnings above 150,000. 

to adjust for the skew and normalizes the data a bit we'll take the log of earnings
```{r}
ggplot(shool_master, aes(x= log(as.numeric(md_reported_ern_10yr)))) + geom_density()
```
Now we can see that the data more closely represents a normalized curve when represented as a log().
This indicate that if we are to use the earnings in this analysis (Which we are) we should probaly explore its representation inits log() form. 

Storing the log value as a column. 
```{r,  message=FALSE, warning=FALSE}
shool_master <- shool_master %>%
  mutate(log_mean_10_yr_earnings = log(md_reported_ern_10yr))
```

This also tells us that when setting the "High" vs "Low" Earning schools we will not want to accept the mean as a splitting point as very high or very low earning shools have the ability to skew the mean value

The first way i would attempt to set the "High" Vs "Low" cut off point is by looking at the data dictionary. 
Looking at the data dictionary income/ earning levels are consistently categorized as the following:

- low-income (less than $30,000)
- middle-income (between $30,000 and $75,000)
- high-income (above $75,000)

Since this is the standard according to the data dictionary i dont think it would be wrong to follow suit in our classification.
SO we'll add this classification as a feature for later use.

```{r, message=FALSE, warning=FALSE}
shool_master <- shool_master %>%
  mutate(Income_level_standard = case_when(as.numeric(md_reported_ern_10yr) < 30000 ~ 'Low',
                             as.numeric(md_reported_ern_10yr) > 75000 ~ 'High',
                             TRUE ~ 'Med'))
```

Using this classification of high vs low however cuts out the mean of my sample population though and a majority of my observations so ill want to address this differently.  

#### _median_
For this ill be splitting it on the median for the entire sample. Selecting not to use mean here as earnings as we saw graphically (above) are highly skewed, median however will help us get a less skewed center. 

```{r}
# median earnings
median_val = median(shool_master$md_reported_ern_10yr)
print(paste("median value is", median_val))
shool_master <- shool_master %>%
  mutate(Inc_High_Low = case_when(md_reported_ern_10yr <= median_val ~ 'Low',
                             TRUE ~ 'High'))

```



### Missing Data
```{r}
# Finding % of nulls
# MostRecentNA <- map(MostRecentRaw, ~mean(is.na(.)))
# MostRecentNA

```

We have quite a few columns that have a high proportion of Null values. 
Some of these these should likely be eliminated from the study unless we have a good reason not to. 



No particularly high missing data in Trends.

```{r}
# unique_keyword_count <- TrendsAppendedDf %>% 
#   group_by(schname) %>%
#   summarise(count_unique = n_distinct(keyword)) %>% 
#   arrange(., desc(count_unique))
```


Number of unique words beeing tracker per school. Some schools have more words tracked for them than others. 
```{r, echo = TRUE}
# Histogram overlaid with kernel density curve
# ggplot(unique_keyword_count, aes(x=count_unique)) + 
#     geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
#                    binwidth=.5,
#                    colour="black", fill="white") +
#     geom_density(alpha=.2, fill="#FF6666")  # Overlay with transparent density plot
```
