---
title: "Econometrics EDA"
author: "Andrew Zinkan"
date: "8/1/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, results= "hide", message=FALSE, warning=FALSE}
# Load initial packages
library(tidyverse)
library(ggplot2)
library(dplyr)
library(vtable)
library(fixest)
library(tidyr)
```

##  Restatment RESEARCH QUESTION:

The College Scorecard was released at the start of September 2015. Among colleges that predominantly grant bachelor’s degrees, did the release of the Scorecard shift student interest to high-earnings colleges relative to low-earnings ones (as proxied by Google searches for keywords associated with those colleges)?

REQ
- You will need to produce at least one regression and one graph for your analysis, and explain them.

# TODO

 - drop all universities that share an exact name with another university. (DONE)
 - make the indices reasonably comparable by standardizing them (for each term, subtract the mean and divide by the standard deviation) (DONE)
 - select colleges that predominantly grant bachelor’s degrees (DONE)
 - set a score card binary for before and after the start of September 2015 (DONE)
 - median earnings of graduates ten years after graduation for each college. But how can we define “high-earning” and “low-earning” colleges? There’s not a single answer - be ready to defend your choice.
 - What level should the data be at? You can leave the data as is, with one row per week per keyword. Or group_by and summarize to put things to one week per college, or one month per college, or one month per keyword, etc. etc.

# Munge
```{r, echo = FALSE, results= "hide", message=FALSE, warning=FALSE}
# Striping the Nulls to NA Values
DataDictRaw <-  read.csv("Data_Exploration/CollegeScorecardDataDictionary.csv", na.strings = c("","NA","NULL",NULL))
IDNameLinkRaw <- read.csv("Data_Exploration/id_name_link.csv", na.strings = c("","NA","NULL",NULL))
MostRecentRaw <- read.csv("Data_Exploration/Most_Recent_Cohorts_Scorecard_Elements.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToFinishRaw <- read.csv("Data_Exploration/trends_up_to_finish.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToInter_1_Raw <- read.csv("Data_Exploration/trends_up_to_inter_1.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToInter_2_Raw <- read.csv("Data_Exploration/trends_up_to_inter_2.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToInter_3_Raw <- read.csv("Data_Exploration/trends_up_to_inter_3.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToInter_4_Raw <- read.csv("Data_Exploration/trends_up_to_inter_4.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToInter_5_Raw <- read.csv("Data_Exploration/trends_up_to_inter_5.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToInter_6_Raw <- read.csv("Data_Exploration/trends_up_to_inter_6.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToUmRaw <- read.csv("Data_Exploration/trends_up_to_UM.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToUphoenixRaw <- read.csv("Data_Exploration/trends_up_to_UPhoenix.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToUtRaw <- read.csv("Data_Exploration/trends_up_to_UT.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToUtmbRaw <- read.csv("Data_Exploration/trends_up_to_UTMB.csv", na.strings = c("","NA","NULL",NULL))
TrendsUpToYorktowneRaw <- read.csv("Data_Exploration/trends_up_to_Yorktowne.csv", na.strings = c("","NA","NULL",NULL))
```

### Drop universities that share an exact name with another university

```{r}
IDNameLinkRaw_Name_Count <- IDNameLinkRaw %>% 
  select(opeid, schname) %>% 
  group_by(opeid) %>% 
  summarise(count_unique = n_distinct(schname))%>% 
  arrange(., desc(count_unique)) %>% 
  filter(count_unique < 2)

shool_filter <- IDNameLinkRaw_Name_Count$opeid

IDNameLinkStage <- filter(IDNameLinkRaw, opeid %in% shool_filter)
```
This results in 3557 with 38 universities removed

### Select colleges that offer primary bachelor degrees
```{r}
Bachelors_primary <- MostRecentRaw %>% 
  select(OPEID, PREDDEG) %>% 
  filter(PREDDEG >= 3)

bach_filter <- Bachelors_primary$OPEID

MostRecentStage <- filter(MostRecentRaw, OPEID %in% bach_filter)

#Remove privacy suppressed data
MostRecentStage <- filter(MostRecentStage, md_earn_wne_p10.REPORTED.EARNINGS != c("PrivacySuppressed"))

# Drop NA if there are any
MostRecentStage <- MostRecentStage %>% 
  drop_na(md_earn_wne_p10.REPORTED.EARNINGS)

# Make contiuouse


```

### Make Indices reasonably comparable
```{r, echo = FALSE, results= "hide", message=FALSE, warning=FALSE}
# Union the Trends Data
TrendsAppendedDf <- rbind(TrendsUpToInter_1_Raw, TrendsUpToInter_2_Raw, TrendsUpToInter_3_Raw, TrendsUpToInter_4_Raw, TrendsUpToInter_5_Raw, TrendsUpToInter_6_Raw, TrendsUpToUmRaw, TrendsUpToUphoenixRaw, TrendsUpToUtmbRaw, TrendsUpToUtmbRaw, TrendsUpToYorktowneRaw, TrendsUpToFinishRaw )
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
# Key Level Mean
key_level_idx <- TrendsAppendedDf %>% 
  select(schname,keyword,index, ) %>% 
  group_by(schname,keyword) %>% 
  summarise(mean_index = mean(index), 
            std_index = sd(index))

# Join raw and idk level
TrendsWMean <- TrendsAppendedDf %>% 
  inner_join(key_level_idx, by = c("schname", "keyword")) %>% 
  select(schid,schname, keyword, monthorweek, index, mean_index, std_index) %>%
  mutate(idx_minus_mean = index-mean_index, standard_idx = idx_minus_mean/std_index)

head(TrendsWMean)
```
### Munge Dates
Score card was added beginning of sept 2015
```{r, message=FALSE, warning=FALSE}
# separate dates
Trends <- separate(TrendsWMean, col=monthorweek, into=c('start_of_week', 'end_of_week'), sep=' - ')
head(Trends)

# Convert to date type
Trends <- Trends %>% 
  mutate(start_of_week = as.Date(start_of_week, format="%Y-%m-%d")) %>% 
  mutate(end_of_week = as.Date(end_of_week, format="%Y-%m-%d"))

# Before and after scorecard indicator
Trends <- Trends %>% 
  mutate(after_score_card = if_else(start_of_week >= as.Date("2015-09-01", format="%Y-%m-%d"), TRUE, FALSE))

head(Trends)
```


### “high-earning” and “low-earning”
how can we define “high-earning” and “low-earning” colleges?
Earing Variables of interest:

- mn_earn_wne_p10
- md_earn_wne_p10-REPORTED-EARNINGS (One that was called to attention for the project)
- pct10_earn_wne_p10
- pct25_earn_wne_p10
- pct75_earn_wne_p10
- pct90_earn_wne_p10
- sd_earn_wne_p10
- count_wne_inc1_p10
- count_wne_inc2_p10
- count_wne_inc3_p10

Distribution on earnings among colleges:
```{r}
# Histogram overlaid with kernel density curve
ggplot(MostRecentStage, aes(x=as.numeric(md_earn_wne_p10.REPORTED.EARNINGS))) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
                   binwidth=100,
                   colour="black", fill="white") +
    geom_density(alpha=.2, fill="#FF6666", stat="count")  # Overlay with transparent density plot
```
```{r}
ggplot(MostRecentStage, aes(x= as.numeric(md_earn_wne_p10.REPORTED.EARNINGS))) + geom_density()
```
```{r}
ggplot(MostRecentStage, aes(x= log(as.numeric(md_earn_wne_p10.REPORTED.EARNINGS)))) + geom_density()
```
```{r}
# create log of earnings
MostRecentStage <- MostRecentStage %>% 
  mutate(log_mean_10_yr_earnings = log(as.numeric(md_earn_wne_p10.REPORTED.EARNINGS)))
```
Everywhere in the data dictionary denotes income levels as the following

- low-income (less than $30,000)
- middle-income (between $30,000 and $75,000)
- high-income (above $75,000)

Since this is the standard according to the data dict i decided to use it as well
```{r}


MostRecentStage <- MostRecentStage %>% 
  mutate(Income_level_standard = case_when(as.numeric(md_earn_wne_p10.REPORTED.EARNINGS) < 30000 ~ 'Low',
                             as.numeric(md_earn_wne_p10.REPORTED.EARNINGS) > 75000 ~ 'High',
                             TRUE ~ 'Med'))
```

### Bring it all together








# EDA

### Missing Data
```{r}
# Finding % of nulls
MostRecentNA <- map(MostRecentRaw, ~mean(is.na(.)))
MostRecentNA

```

We have quite a few columns that have a high proportion of Null values. 
Some of these these should likely be eliminated from the study unless we have a good reason not to. 



No particularly high missing data in Trends.

```{r}
unique_keyword_count <- TrendsAppendedDf %>% 
  group_by(schname) %>%
  summarise(count_unique = n_distinct(keyword)) %>% 
  arrange(., desc(count_unique))
```


Number of unique words beeing tracker per school. Some schools have more words tracked for them than others. 
```{r, echo = TRUE}
# Histogram overlaid with kernel density curve
ggplot(unique_keyword_count, aes(x=count_unique)) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
                   binwidth=.5,
                   colour="black", fill="white") +
    geom_density(alpha=.2, fill="#FF6666")  # Overlay with transparent density plot
```
